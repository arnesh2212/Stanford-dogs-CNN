{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = os.listdir('Images')\n",
    "names = np.array(dir)\n",
    "#print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (200, 200)\n",
    "batch_size = 32\n",
    "\n",
    "training = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"Images\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"Images\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython import display\n",
    "#display.Image(\"Images/n02086079-Pekinese/n02086079_146.jpg\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in training.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(int(labels[i]))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "        \n",
    "    ]\n",
    ")\n",
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    # Image augmentation block\n",
    "    x = data_augmentation(inputs)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [128, 256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 200, 200, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "rescaling_2 (Rescaling)         (None, 200, 200, 3)  0           sequential_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 100, 100, 32) 896         rescaling_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 100, 100, 32) 128         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 100, 100, 32) 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 100, 100, 64) 18496       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 100, 100, 64) 256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 100, 100, 64) 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 100, 100, 64) 0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_18 (SeparableC (None, 100, 100, 128 8896        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 100, 100, 128 512         separable_conv2d_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 100, 100, 128 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_19 (SeparableC (None, 100, 100, 128 17664       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 100, 100, 128 512         separable_conv2d_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 50, 50, 128)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 50, 50, 128)  8320        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 50, 50, 128)  0           max_pooling2d_8[0][0]            \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 50, 50, 128)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_20 (SeparableC (None, 50, 50, 256)  34176       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 50, 50, 256)  1024        separable_conv2d_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 50, 50, 256)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_21 (SeparableC (None, 50, 50, 256)  68096       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 50, 50, 256)  1024        separable_conv2d_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 25, 25, 256)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 256)  33024       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 25, 25, 256)  0           max_pooling2d_9[0][0]            \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 25, 25, 256)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_22 (SeparableC (None, 25, 25, 512)  133888      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 25, 25, 512)  2048        separable_conv2d_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 25, 25, 512)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_23 (SeparableC (None, 25, 25, 512)  267264      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 25, 25, 512)  2048        separable_conv2d_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 13, 13, 512)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 13, 13, 512)  131584      add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 13, 13, 512)  0           max_pooling2d_10[0][0]           \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 13, 13, 512)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_24 (SeparableC (None, 13, 13, 728)  378072      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 13, 13, 728)  2912        separable_conv2d_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 13, 13, 728)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_25 (SeparableC (None, 13, 13, 728)  537264      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 13, 13, 728)  2912        separable_conv2d_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 7, 7, 728)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 7, 7, 728)    373464      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 7, 7, 728)    0           max_pooling2d_11[0][0]           \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_26 (SeparableC (None, 7, 7, 1024)   753048      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 7, 7, 1024)   4096        separable_conv2d_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 7, 1024)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 1024)         0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 120)          123000      dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,904,624\n",
      "Trainable params: 2,895,888\n",
      "Non-trainable params: 8,736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = make_model(input_shape=image_size + (3,), num_classes=120)\n",
    "keras.utils.plot_model(model, show_shapes=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "515/515 [==============================] - 102s 196ms/step - loss: 3.5490 - accuracy: 0.1363 - val_loss: 4.8401 - val_accuracy: 0.0522\n",
      "Epoch 2/50\n",
      "515/515 [==============================] - 97s 188ms/step - loss: 3.3213 - accuracy: 0.1768 - val_loss: 3.8024 - val_accuracy: 0.1193\n",
      "Epoch 3/50\n",
      "515/515 [==============================] - 96s 187ms/step - loss: 3.1296 - accuracy: 0.2077 - val_loss: 3.4142 - val_accuracy: 0.1747\n",
      "Epoch 4/50\n",
      "515/515 [==============================] - 97s 187ms/step - loss: 2.9159 - accuracy: 0.2484 - val_loss: 3.7050 - val_accuracy: 0.1608\n",
      "Epoch 5/50\n",
      "515/515 [==============================] - 96s 187ms/step - loss: 2.7281 - accuracy: 0.2889 - val_loss: 3.1867 - val_accuracy: 0.2021\n",
      "Epoch 6/50\n",
      "515/515 [==============================] - 96s 187ms/step - loss: 2.5630 - accuracy: 0.3199 - val_loss: 4.2344 - val_accuracy: 0.1528\n",
      "Epoch 7/50\n",
      "515/515 [==============================] - 97s 187ms/step - loss: 2.3965 - accuracy: 0.3513 - val_loss: 3.0488 - val_accuracy: 0.2478\n",
      "Epoch 8/50\n",
      "515/515 [==============================] - 97s 187ms/step - loss: 2.2637 - accuracy: 0.3847 - val_loss: 2.6318 - val_accuracy: 0.3243\n",
      "Epoch 9/50\n",
      "515/515 [==============================] - 97s 189ms/step - loss: 2.1418 - accuracy: 0.4127 - val_loss: 2.5860 - val_accuracy: 0.3229\n",
      "Epoch 10/50\n",
      "515/515 [==============================] - 97s 188ms/step - loss: 2.0492 - accuracy: 0.4321 - val_loss: 2.8132 - val_accuracy: 0.2959\n",
      "Epoch 11/50\n",
      "515/515 [==============================] - 98s 191ms/step - loss: 1.9295 - accuracy: 0.4561 - val_loss: 2.5757 - val_accuracy: 0.3523\n",
      "Epoch 12/50\n",
      "515/515 [==============================] - 100s 194ms/step - loss: 1.8386 - accuracy: 0.4791 - val_loss: 2.6812 - val_accuracy: 0.3506\n",
      "Epoch 13/50\n",
      "515/515 [==============================] - 99s 191ms/step - loss: 1.7648 - accuracy: 0.4961 - val_loss: 3.1031 - val_accuracy: 0.2877\n",
      "Epoch 14/50\n",
      "515/515 [==============================] - 99s 193ms/step - loss: 1.6929 - accuracy: 0.5167 - val_loss: 2.4085 - val_accuracy: 0.3992\n",
      "Epoch 15/50\n",
      "515/515 [==============================] - 99s 192ms/step - loss: 1.6336 - accuracy: 0.5302 - val_loss: 2.4747 - val_accuracy: 0.3839\n",
      "Epoch 16/50\n",
      "515/515 [==============================] - 100s 194ms/step - loss: 1.5400 - accuracy: 0.5533 - val_loss: 2.3655 - val_accuracy: 0.3827\n",
      "Epoch 17/50\n",
      "515/515 [==============================] - 101s 197ms/step - loss: 1.4968 - accuracy: 0.5617 - val_loss: 2.7157 - val_accuracy: 0.3550\n",
      "Epoch 18/50\n",
      "515/515 [==============================] - 100s 194ms/step - loss: 1.4340 - accuracy: 0.5806 - val_loss: 2.9948 - val_accuracy: 0.3307\n",
      "Epoch 19/50\n",
      "515/515 [==============================] - 101s 197ms/step - loss: 1.3780 - accuracy: 0.5899 - val_loss: 2.4223 - val_accuracy: 0.3861\n",
      "Epoch 20/50\n",
      "515/515 [==============================] - 102s 197ms/step - loss: 1.3227 - accuracy: 0.6084 - val_loss: 2.5673 - val_accuracy: 0.4339\n",
      "Epoch 21/50\n",
      "515/515 [==============================] - 101s 195ms/step - loss: 1.2788 - accuracy: 0.6200 - val_loss: 2.2368 - val_accuracy: 0.4385\n",
      "Epoch 22/50\n",
      "515/515 [==============================] - 100s 194ms/step - loss: 1.2339 - accuracy: 0.6292 - val_loss: 2.6540 - val_accuracy: 0.3943\n",
      "Epoch 23/50\n",
      "515/515 [==============================] - 101s 197ms/step - loss: 1.1805 - accuracy: 0.6425 - val_loss: 2.1569 - val_accuracy: 0.4665\n",
      "Epoch 24/50\n",
      "515/515 [==============================] - 102s 197ms/step - loss: 1.1392 - accuracy: 0.6522 - val_loss: 2.6265 - val_accuracy: 0.4004\n",
      "Epoch 25/50\n",
      "515/515 [==============================] - 102s 198ms/step - loss: 1.0800 - accuracy: 0.6756 - val_loss: 2.2460 - val_accuracy: 0.4478\n",
      "Epoch 26/50\n",
      "515/515 [==============================] - 101s 195ms/step - loss: 1.0559 - accuracy: 0.6768 - val_loss: 2.3725 - val_accuracy: 0.4315\n",
      "Epoch 27/50\n",
      "515/515 [==============================] - 102s 198ms/step - loss: 1.0093 - accuracy: 0.6928 - val_loss: 2.6590 - val_accuracy: 0.4133\n",
      "Epoch 28/50\n",
      "515/515 [==============================] - 100s 193ms/step - loss: 0.9613 - accuracy: 0.7007 - val_loss: 2.4897 - val_accuracy: 0.4322\n",
      "Epoch 29/50\n",
      "515/515 [==============================] - 101s 196ms/step - loss: 0.9295 - accuracy: 0.7134 - val_loss: 2.2582 - val_accuracy: 0.4570\n",
      "Epoch 30/50\n",
      "515/515 [==============================] - 101s 197ms/step - loss: 0.9046 - accuracy: 0.7173 - val_loss: 2.4634 - val_accuracy: 0.4594\n",
      "Epoch 31/50\n",
      "515/515 [==============================] - 101s 195ms/step - loss: 0.8606 - accuracy: 0.7365 - val_loss: 2.4454 - val_accuracy: 0.4473\n",
      "Epoch 32/50\n",
      "515/515 [==============================] - 100s 194ms/step - loss: 0.8531 - accuracy: 0.7351 - val_loss: 2.5606 - val_accuracy: 0.4504\n",
      "Epoch 33/50\n",
      "515/515 [==============================] - 101s 196ms/step - loss: 0.8062 - accuracy: 0.7507 - val_loss: 2.3206 - val_accuracy: 0.4526\n",
      "Epoch 34/50\n",
      "515/515 [==============================] - 100s 195ms/step - loss: 0.7737 - accuracy: 0.7578 - val_loss: 2.6829 - val_accuracy: 0.4339\n",
      "Epoch 35/50\n",
      "515/515 [==============================] - 100s 194ms/step - loss: 0.7491 - accuracy: 0.7609 - val_loss: 2.1980 - val_accuracy: 0.4917\n",
      "Epoch 36/50\n",
      "515/515 [==============================] - 102s 198ms/step - loss: 0.7171 - accuracy: 0.7731 - val_loss: 2.7488 - val_accuracy: 0.4264\n",
      "Epoch 37/50\n",
      "515/515 [==============================] - 101s 195ms/step - loss: 0.6984 - accuracy: 0.7797 - val_loss: 2.7862 - val_accuracy: 0.4483\n",
      "Epoch 38/50\n",
      "515/515 [==============================] - 100s 194ms/step - loss: 0.6858 - accuracy: 0.7819 - val_loss: 2.5316 - val_accuracy: 0.4662\n",
      "Epoch 39/50\n",
      "515/515 [==============================] - 101s 196ms/step - loss: 0.6553 - accuracy: 0.7925 - val_loss: 2.5619 - val_accuracy: 0.4446\n",
      "Epoch 40/50\n",
      "515/515 [==============================] - 102s 199ms/step - loss: 0.6230 - accuracy: 0.8007 - val_loss: 2.5732 - val_accuracy: 0.4546\n",
      "Epoch 41/50\n",
      "515/515 [==============================] - 103s 199ms/step - loss: 0.6064 - accuracy: 0.8047 - val_loss: 2.7202 - val_accuracy: 0.4602\n",
      "Epoch 42/50\n",
      "515/515 [==============================] - 99s 192ms/step - loss: 0.5759 - accuracy: 0.8182 - val_loss: 2.5672 - val_accuracy: 0.4653\n",
      "Epoch 43/50\n",
      "515/515 [==============================] - 97s 189ms/step - loss: 0.5754 - accuracy: 0.8142 - val_loss: 2.5051 - val_accuracy: 0.4577\n",
      "Epoch 44/50\n",
      "515/515 [==============================] - 98s 191ms/step - loss: 0.5452 - accuracy: 0.8252 - val_loss: 2.2434 - val_accuracy: 0.5058\n",
      "Epoch 45/50\n",
      "515/515 [==============================] - 100s 193ms/step - loss: 0.5494 - accuracy: 0.8226 - val_loss: 2.7445 - val_accuracy: 0.4521\n",
      "Epoch 46/50\n",
      "515/515 [==============================] - 101s 195ms/step - loss: 0.5067 - accuracy: 0.8389 - val_loss: 2.6497 - val_accuracy: 0.4772\n",
      "Epoch 47/50\n",
      "515/515 [==============================] - 99s 193ms/step - loss: 0.5073 - accuracy: 0.8403 - val_loss: 3.2320 - val_accuracy: 0.4334\n",
      "Epoch 48/50\n",
      "515/515 [==============================] - 97s 187ms/step - loss: 0.5019 - accuracy: 0.8379 - val_loss: 2.6125 - val_accuracy: 0.4716\n",
      "Epoch 49/50\n",
      "515/515 [==============================] - 97s 187ms/step - loss: 0.4698 - accuracy: 0.8489 - val_loss: 2.8617 - val_accuracy: 0.4359\n",
      "Epoch 50/50\n",
      "515/515 [==============================] - 99s 192ms/step - loss: 0.4549 - accuracy: 0.8558 - val_loss: 2.6601 - val_accuracy: 0.4752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2459a053460>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    training, epochs=50, callbacks=callbacks, validation_data=validation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n02110958-pug\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import image\n",
    " \n",
    "# predicting images\n",
    "path = \"pug.jpeg\"\n",
    "img = image.load_img(path, target_size=(200, 200))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "images = np.vstack([x])\n",
    "classes = model.predict(images, batch_size=10)\n",
    "\n",
    "print(names[np.argmax(classes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n02110958-pug\n"
     ]
    }
   ],
   "source": [
    "best_model = keras.models.load_model(\"save_at_50.h5\")\n",
    "path = \"pug.jpeg\"\n",
    "img = image.load_img(path, target_size=(200, 200))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "images = np.vstack([x])\n",
    "classes = best_model.predict(images, batch_size=10)\n",
    "\n",
    "print(names[np.argmax(classes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
